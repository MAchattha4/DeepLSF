{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "seed_value= 1111\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.set_random_seed(seed_value)\n",
    "\n",
    "import warnings\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "# from sklearn.metrics import mean_absolute_percentage_error\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Input,LSTM, Dense, Flatten, Conv1D, Lambda, Reshape, RepeatVector\n",
    "from keras.layers.merge import concatenate, multiply,add\n",
    "from keras import regularizers\n",
    "from keras.initializers import glorot_uniform\n",
    "from tqdm import tqdm\n",
    "from keras import regularizers\n",
    "from keras.models import load_model\n",
    "import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import random as python_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function to make input window for training and test sets\n",
    "\n",
    "def make_input(data,window_size,horizon=1):\n",
    "    length=data.shape[0]\n",
    "    y = np.zeros([length-window_size+1-horizon,horizon])\n",
    "    output=np.zeros([length-window_size+1-horizon,window_size])\n",
    "    for i in range(length-window_size-horizon+1):\n",
    "        output[i:i+1,:]=data[i:i+window_size]\n",
    "        y[i,:]= data[i+window_size:i+window_size+horizon]\n",
    "    return output.reshape(output.shape[0],window_size), y\n",
    "\n",
    "def make_k_input(data,horizon):\n",
    "    length = data.shape[0]\n",
    "    output= np.zeros([length+1-horizon,horizon])\n",
    "    for i in range(length-window_size-horizon+1):\n",
    "        output[i:i+1,:]=data[i:i+horizon]\n",
    "    return output.reshape(output.shape[0],horizon)\n",
    "\n",
    "def nonov_make_input(data,window_size,horizon=1):\n",
    "    length=data.shape[0]-window_size\n",
    "    loop=length//horizon\n",
    "    extra = length%horizon\n",
    "\n",
    "    data = np.append(data,np.zeros([horizon-extra]))\n",
    "\n",
    "    if extra ==0:\n",
    "        i_val = loop\n",
    "    else:\n",
    "        i_val=loop+1\n",
    "        \n",
    "    output=np.zeros([i_val,window_size])\n",
    "    y=np.zeros([i_val,horizon])\n",
    "    for i in range(i_val):\n",
    "        output[i:i+1,:]=data[i*horizon:(i*horizon)+window_size]\n",
    "        y[i,:]= data[(i*horizon)+window_size:(i*horizon)+window_size+horizon]\n",
    "        \n",
    "    return output.reshape(output.shape[0],window_size), y\n",
    "\n",
    "def nonov_make_k_input(data,horizon):\n",
    "    length = data.shape[0]\n",
    "    loop=length//horizon\n",
    "    extra = length%horizon\n",
    "    data_app = np.repeat(data[-1],(horizon-extra))\n",
    "    data = np.append(data,data_app)    \n",
    "\n",
    "    if extra ==0:\n",
    "        i_val = loop\n",
    "    else:\n",
    "        i_val=loop+1\n",
    "    output=np.zeros([i_val,horizon])\n",
    "    for i in range(i_val):\n",
    "        output[i:i+1,:]=data[(i*horizon):(i*horizon)+horizon]\n",
    "    return output.reshape(output.shape[0],horizon)\n",
    "\n",
    "\n",
    "def metrics(pred,gt):\n",
    "    l = pred.shape[1]\n",
    "#     print(l)\n",
    "    err_mse = np.zeros((l))\n",
    "    err_mae = np.zeros((l))\n",
    "\n",
    "    for i in range(l):\n",
    "        err_mse[i] = mse(pred[:,i],gt[:,i])\n",
    "        err_mae[i] = mae(pred[:,i],gt[:,i])\n",
    "        \n",
    "    return np.sqrt(np.mean(err_mse)),np.mean(err_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------variables to change according to dataset-------------------------\n",
    "\n",
    "dataset = \"traffic\" # can be chosen from [\"traffic\",\"nasdaq\",\"energy\"]\n",
    "\n",
    "# for traffic, horizon can be choosen from [3,6,9] for other datasets horizon value can be chosen [3,6,12]\n",
    "horizon = 9\n",
    "\n",
    "knowledge_pred_path ='knowledge_preds/'+dataset+'/horizon_'+str(horizon)+'/t_preds.csv' # according to directory containing knowledge predictions\n",
    "data_path = '/data/'+dataset # according to path containing data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------vairables initialization according to dataset---------------------\n",
    "\n",
    "\n",
    "if dataset==\"traffic\":\n",
    "    window_size = 12   \n",
    "    data = np.asarray(pd.read_csv(data_path+'.csv',header=None))\n",
    "    knowledge_preds = np.asarray(pd.read_csv(knowledge_pred_path,header=None))\n",
    "    n_val=2880         # index from where validation set starts\n",
    "    n_test=1440        # index from where test set starts\n",
    "    data_length = data.shape[1]\n",
    "    t_size=data.shape[0]\n",
    "    output = np.zeros((n_test,data_length))\n",
    "    final_in_train = np.zeros([1,window_size,1])\n",
    "    final_in_val =final_in_train\n",
    "    final_in_test=final_in_train\n",
    "    final_lbl_train = np.zeros([1,horizon])\n",
    "    final_lbl_val = final_lbl_train\n",
    "    final_lbl_test = final_lbl_train\n",
    "    final_p_train = final_lbl_train\n",
    "    final_p_val= final_p_train\n",
    "    final_p_test = final_p_train\n",
    "elif dataset==\"nasdaq\":\n",
    "    window_size = 180\n",
    "    data = np.asarray(pd.read_csv(data_path+'.csv'))\n",
    "    knowledge_preds = np.asarray(pd.read_csv(knowledge_pred_path,header=None))\n",
    "    n_val = 4056       # index from where validation set starts\n",
    "    n_test = 2028      # index from where validation set starts\n",
    "    data_length = data.shape[1]\n",
    "    t_size=data.shape[0]\n",
    "    output = np.zeros((n_test,data_length))\n",
    "    final_in_train = np.zeros([1,window_size,1])\n",
    "    final_in_val =final_in_train\n",
    "    final_in_test=final_in_train\n",
    "    final_lbl_train = np.zeros([1,horizon])\n",
    "    final_lbl_val = final_lbl_train\n",
    "    final_lbl_test = final_lbl_train\n",
    "    final_p_train = final_lbl_train\n",
    "    final_p_val= final_p_train\n",
    "    final_p_test = final_p_train\n",
    "    \n",
    "else:\n",
    "    window_size = 144    \n",
    "    data = np.asarray(pd.read_csv(data_path+'.txt',header=None))\n",
    "    knowledge_preds = np.asarray(pd.read_csv(knowledge_pred_path,header=None))\n",
    "    n_val = 3947       # index from where validation set starts\n",
    "    n_test = 1973      # index from where validation set starts\n",
    "    data_length = data.shape[1]\n",
    "    t_size=data.shape[0]\n",
    "    output = np.zeros((n_test,data_length))\n",
    "    final_in_train = np.zeros([1,window_size,1])\n",
    "    final_in_val =final_in_train\n",
    "    final_in_test=final_in_train\n",
    "    final_lbl_train = np.zeros([1,horizon])\n",
    "    final_lbl_val = final_lbl_train\n",
    "    final_lbl_test = final_lbl_train\n",
    "    final_p_train = final_lbl_train\n",
    "    final_p_val= final_p_train\n",
    "    final_p_test = final_p_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------Data preprocessing and preparation--------------------------\n",
    "\n",
    "if dataset ==\"traffic\":\n",
    "\n",
    "    with tqdm(total=data_length) as pbar:\n",
    "        for i in range(data_length):\n",
    "            current_row= data[:,i]\n",
    "\n",
    "\n",
    "            train = current_row[:-n_val]\n",
    "            val = current_row[-(n_val+window_size):-n_test]\n",
    "            test = current_row[-(n_test+window_size):]\n",
    "            train_sequence = make_input(train, window_size,horizon)\n",
    "            val_sequence = make_input(val,window_size,horizon)\n",
    "            test_sequence = nonov_make_input(test,window_size,horizon)\n",
    "\n",
    "            temp_train_x=train_sequence[0]\n",
    "            temp_train_y=train_sequence[1]\n",
    "            final_in_train =np.append(final_in_train,temp_train_x.reshape(temp_train_x.shape[0],temp_train_x.shape[1],1),axis=0)\n",
    "            final_lbl_train = np.append(final_lbl_train,temp_train_y,axis=0)\n",
    "\n",
    "            temp_val_x=val_sequence[0]\n",
    "            temp_val_y=val_sequence[1] \n",
    "            final_in_val =np.append(final_in_val,temp_val_x.reshape(temp_val_x.shape[0],temp_val_x.shape[1],1),axis=0)\n",
    "            final_lbl_val = np.append(final_lbl_val,temp_val_y,axis=0)\n",
    "\n",
    "            temp_test_x=test_sequence[0]\n",
    "            temp_test_y=test_sequence[1]\n",
    "            final_in_test =np.append(final_in_test,temp_test_x.reshape(temp_test_x.shape[0],temp_test_x.shape[1],1),axis=0)\n",
    "            final_lbl_test = np.append(final_lbl_test,temp_test_y,axis=0)\n",
    "\n",
    "            current_pred= knowledge_preds[:,i]\n",
    "            series_p=current_pred\n",
    "            series_pred=series_p[:-n_test]    \n",
    "            train_p = series_pred[:-n_val]                                        \n",
    "            val_p = series_pred[-n_val:]\n",
    "            test_p = series_p[-n_test:]\n",
    "            train_pred = make_k_input(train_p,horizon)\n",
    "            val_pred = make_k_input(val_p,horizon)\n",
    "            test_pred = nonov_make_k_input(test_p,horizon)\n",
    "\n",
    "            temp_train_p_x=train_pred\n",
    "            final_p_train =np.append(final_p_train,temp_train_p_x,axis=0)\n",
    "\n",
    "            temp_val_p_x=val_pred\n",
    "            final_p_val =np.append(final_p_val,temp_val_p_x,axis=0)\n",
    "\n",
    "            temp_test_p_x=test_pred\n",
    "            final_p_test =np.append(final_p_test,temp_test_p_x,axis=0)\n",
    "\n",
    "            pbar.update(1)\n",
    "    final_in_train = final_in_train[1:,:,:]\n",
    "    final_in_val = final_in_val[1:,:,:]\n",
    "    final_in_test = final_in_test[1:,:,:]\n",
    "    final_lbl_train = final_lbl_train[1:,:]\n",
    "    final_lbl_val = final_lbl_val[1:,:]\n",
    "    final_lbl_test = final_lbl_test[1:,:]\n",
    "    final_p_train = final_p_train[1:,:]\n",
    "    final_p_val = final_p_val[1:,:]\n",
    "    final_p_test = final_p_test[1:,:]\n",
    "else:\n",
    "    \n",
    "    with tqdm(total=data_length) as pbar:\n",
    "        for i in range(data_length):\n",
    "            current_row= data[:,i]\n",
    "\n",
    "            train = current_row[:-n_val]\n",
    "            val = current_row[-(n_val+window_size):-n_test]\n",
    "            test = current_row[-(n_test+window_size):]\n",
    "            train_sequence = make_input(train, window_size,horizon)\n",
    "            val_sequence = make_input(val,window_size,horizon)\n",
    "            test_sequence = nonov_make_input(test,window_size,horizon)\n",
    "\n",
    "            temp_train_x=train_sequence[0]    \n",
    "            min_in = temp_train_x.min(1).reshape(temp_train_x.shape[0],1)\n",
    "            max_in = temp_train_x.max(1).reshape(temp_train_x.shape[0],1)\n",
    "            denom = (max_in-min_in)\n",
    "            a = np.where(denom == 0)[0]\n",
    "            denom[a] = max_in[a] \n",
    "            a = np.where(denom == 0)[0]\n",
    "            if a.size >0:\n",
    "                denom[a]=1\n",
    "            temp_train_x = (temp_train_x-min_in)/denom\n",
    "            temp_train_x=temp_train_x.reshape(temp_train_x.shape[0],temp_train_x.shape[1],1)\n",
    "            temp_train_y=(train_sequence[1]-min_in)/denom\n",
    "            final_in_train =np.append(final_in_train,temp_train_x,axis=0)\n",
    "            final_lbl_train = np.append(final_lbl_train,temp_train_y,axis=0)\n",
    "\n",
    "            temp_val_x=val_sequence[0]    \n",
    "            min_in = temp_val_x.min(1).reshape(temp_val_x.shape[0],1)\n",
    "            max_in = temp_val_x.max(1).reshape(temp_val_x.shape[0],1)\n",
    "            denom = (max_in-min_in)\n",
    "            a = np.where(denom == 0)[0]\n",
    "            denom[a] = max_in[a] \n",
    "            temp_val_x = (temp_val_x-min_in)/denom \n",
    "            temp_val_x=temp_val_x.reshape(temp_val_x.shape[0],temp_val_x.shape[1],1)\n",
    "            temp_val_y=(val_sequence[1]-min_in)/denom\n",
    "            final_in_val =np.append(final_in_val,temp_val_x,axis=0)\n",
    "            final_lbl_val = np.append(final_lbl_val,temp_val_y,axis=0)\n",
    "\n",
    "            temp_test_x=test_sequence[0]    \n",
    "            min_in_test = temp_test_x.min(1).reshape(temp_test_x.shape[0],1)\n",
    "            max_in_test = temp_test_x.max(1).reshape(temp_test_x.shape[0],1)\n",
    "            denom_test = (max_in_test-min_in_test)\n",
    "            a = np.where(denom_test == 0)[0]\n",
    "            denom_test[a] = max_in_test[a] \n",
    "            temp_test_x = (temp_test_x-min_in_test)/denom_test\n",
    "            temp_test_x=temp_test_x.reshape(temp_test_x.shape[0],temp_test_x.shape[1],1)\n",
    "            temp_test_y=(test_sequence[1]-min_in_test)/denom_test\n",
    "\n",
    "            final_in_test =np.append(final_in_test,temp_test_x,axis=0)\n",
    "            final_lbl_test = np.append(final_lbl_test,temp_test_y,axis=0)\n",
    "\n",
    "            current_pred= knowledge_preds[:(t_size-window_size),i]\n",
    "            train_p = current_pred[:-n_val]                                        \n",
    "            val_p = current_pred[-n_val:-n_test]\n",
    "            test_p = current_pred[-n_test:]\n",
    "            train_pred = make_k_input(train_p,horizon)\n",
    "            val_pred = make_k_input(val_p,horizon)\n",
    "            test_pred = nonov_make_k_input(test_p,horizon)\n",
    "\n",
    "            temp_train_p_x=train_pred\n",
    "            min_in = temp_train_p_x.min(1).reshape(temp_train_p_x.shape[0],1)\n",
    "            max_in = temp_train_p_x.max(1).reshape(temp_train_p_x.shape[0],1)\n",
    "            denom = (max_in-min_in)\n",
    "            a = np.where(denom == 0)[0]\n",
    "            denom[a] = max_in[a] #--------------------------------------check\n",
    "            a = np.where(denom == 0)[0]\n",
    "            if len(a)>0:\n",
    "                denom[a]=1\n",
    "            temp_train_p_x = (temp_train_p_x-min_in)/denom \n",
    "            temp_train_p_x[a] =0.5\n",
    "\n",
    "            final_p_train =np.append(final_p_train,temp_train_p_x,axis=0)\n",
    "\n",
    "            temp_val_p_x=val_pred\n",
    "            min_in = temp_val_p_x.min(1).reshape(temp_val_p_x.shape[0],1)\n",
    "            max_in = temp_val_p_x.max(1).reshape(temp_val_p_x.shape[0],1)\n",
    "            denom = (max_in-min_in)\n",
    "            a = np.where(denom == 0)[0]\n",
    "            denom[a] = max_in[a] #--------------------------------------check\n",
    "            a = np.where(denom == 0)[0]\n",
    "            if len(a)>0:\n",
    "                denom[a]=1\n",
    "            temp_val_p_x = (temp_val_p_x-min_in)/denom\n",
    "            temp_val_p_x[a] = 0.5\n",
    "\n",
    "            final_p_val =np.append(final_p_val,temp_val_p_x,axis=0)\n",
    "\n",
    "            temp_test_p_x=test_pred\n",
    "            min_in = temp_test_p_x.min(1).reshape(temp_test_p_x.shape[0],1)\n",
    "            max_in = temp_test_p_x.max(1).reshape(temp_test_p_x.shape[0],1)\n",
    "            denom = (max_in-min_in)\n",
    "            a = np.where(denom == 0)[0]\n",
    "            denom[a] = max_in[a] #--------------------------------------check\n",
    "            a = np.where(denom == 0)[0]\n",
    "            if len(a)>0:\n",
    "                denom[a]=1\n",
    "            temp_test_p_x = (temp_test_p_x-min_in)/denom\n",
    "            temp_test_p_x[a] = 0.5\n",
    "\n",
    "\n",
    "\n",
    "            final_p_test =np.append(final_p_test,temp_test_p_x,axis=0)\n",
    "\n",
    "            pbar.update(1)\n",
    "    final_in_train = final_in_train[1:,:,:]\n",
    "    final_in_val = final_in_val[1:,:,:]\n",
    "    final_in_test = final_in_test[1:,:,:]\n",
    "    final_lbl_train = final_lbl_train[1:,:]\n",
    "    final_lbl_val = final_lbl_val[1:,:]\n",
    "    final_lbl_test = final_lbl_test[1:,:]\n",
    "    final_p_train = final_p_train[1:,:]\n",
    "    final_p_val = final_p_val[1:,:]\n",
    "    final_p_test = final_p_test[1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "K.clear_session()  \n",
    "encoder=load_model('/DeepLSF_models/'+dataset+'/horizon_'+str(horizon)+'/encoder_h'+str(horizon)+'.h5',compile=False)\n",
    "model=load_model('/DeepLSF_models/'+dataset+'/horizon_'+str(horizon)+'/'+str(horizon)+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------test set eva\n",
    "\n",
    "\n",
    "for i in range(data_length):\n",
    "    \n",
    "    if dataset==\"traffic\":\n",
    "        current_row= data[:,i]\n",
    "        series_d = current_row\n",
    "        test = series_d[-(n_test+window_size):]\n",
    "        test_sequence = nonov_make_input(test,window_size,horizon)\n",
    "\n",
    "        temp_test_x=test_sequence[0]\n",
    "        temp_test_y=test_sequence[1]\n",
    "\n",
    "\n",
    "        current_pred= knowledge_preds[:,i]\n",
    "        \n",
    "        test_p = current_pred[-n_test:]\n",
    "        test_k_pred = nonov_make_k_input(test_p,horizon)        \n",
    "        temp_auto_test_p=np.array(encoder.predict(test_k_pred))\n",
    "\n",
    "        pred = model.predict({'input_data':temp_test_x.reshape(temp_test_x.shape[0],temp_test_x.shape[1],1), 'input_pred':temp_auto_test_p})\n",
    "   \n",
    "        prediction = pred.flatten()\n",
    "\n",
    "        output[:,i]=np.transpose(prediction)   \n",
    "        \n",
    "        \n",
    "    else:\n",
    "        current_row= data[:,i]\n",
    "        series_d = current_row\n",
    "        test = series_d[-(n_test+window_size):]\n",
    "        test_sequence = nonov_make_input(test,window_size,horizon)\n",
    "\n",
    "        temp_test_x=test_sequence[0]    \n",
    "\n",
    "        min_in_test = temp_test_x.min(1).reshape(temp_test_x.shape[0],1)\n",
    "        max_in_test = temp_test_x.max(1).reshape(temp_test_x.shape[0],1)\n",
    "        denom_test = (max_in_test-min_in_test)\n",
    "        a = np.where(denom_test == 0)[0]\n",
    "        denom_test[a] = max_in_test[a]  #----------------------------------check\n",
    "        temp_test_x = (temp_test_x-min_in_test)/denom_test\n",
    "        temp_test_x=temp_test_x.reshape(temp_test_x.shape[0],temp_test_x.shape[1],1)\n",
    "        temp_test_y=(test_sequence[1]-min_in_test)/denom_test\n",
    "\n",
    "        current_pred= knowledge_preds[:,i]\n",
    "        \n",
    "        test_p = current_pred[-n_test:]\n",
    "        test_k_pred = nonov_make_k_input(test_p,horizon)\n",
    "\n",
    "        temp_test_p_x=test_k_pred\n",
    "        min_in = temp_test_p_x.min(1).reshape(temp_test_p_x.shape[0],1)\n",
    "        max_in = temp_test_p_x.max(1).reshape(temp_test_p_x.shape[0],1)\n",
    "        denom = (max_in-min_in)\n",
    "        a = np.where(denom == 0)[0]\n",
    "        denom[a] = max_in[a] #--------------------------------------check\n",
    "        a = np.where(denom == 0)[0]\n",
    "        if len(a)>0:\n",
    "            denom[a]=1\n",
    "        temp_test_p_x = (temp_test_p_x-min_in)/denom\n",
    "        temp_test_p_x[a] = 0.5\n",
    "\n",
    "        temp_auto_test_p=np.array(encoder.predict(temp_test_p_x))\n",
    "\n",
    "        pred = model.predict({'input_data':temp_test_x, 'input_pred':temp_auto_test_p})\n",
    "        prediction = pred*(max_in_test-min_in_test)+min_in_test\n",
    "        prediction = prediction.flatten()[:n_test]\n",
    "\n",
    "        output[:,i]=np.transpose(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1, temp2= metrics(output,data[-n_test:,:])\n",
    "[temp1,temp2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
